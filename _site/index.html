<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Institute for Machine Learning @ JKU</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/duo-iml/assets/img/favicon.ico">
<link rel="stylesheet" href="/duo-iml/assets/css/main.css">

<link rel="canonical" href="/duo-iml/">

<!-- Theming-->




    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/duo-iml/">
       <span>Institute</span> for Machine  Learning @ JKU
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/duo-iml/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/duo-iml/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/duo-iml/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/duo-iml/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/duo-iml/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <article>
    
    <div class="profile float-">
      
        <img class="img-fluid z-depth-1 rounded" src="/duo-iml/assets/img/jku_pic.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>Write your biography here. Tell the world about yourself. Link to your favorite <a href="http://reddit.com" target="\_blank">subreddit</a>. You can put a picture in, too. The code is already in, just name your picture <code class="language-plaintext highlighter-rouge">prof_pic.jpg</code> and put it in the <code class="language-plaintext highlighter-rouge">img/</code> folder.</p>

<p>Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing <code class="language-plaintext highlighter-rouge">profile</code> property of the YAML header of your <code class="language-plaintext highlighter-rouge">_pages/about.md</code>. Edit <code class="language-plaintext highlighter-rouge">_bibliography/papers.bib</code> and Jekyll will render your <a href="/al-folio/publications/">publications page</a> automatically.</p>

<p>Link to your social media connections, too. This theme is set up to use <a href="http://fortawesome.github.io/Font-Awesome/" target="\_blank">Font Awesome icons</a> and <a href="https://jpswalsh.github.io/academicons/" target="\_blank">Academicons</a>, like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.</p>

    </div>
    <div class="row mt-3">
        <div class="col-sm mt-3 mt-md-0">
            
              <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Oct 22, 2020</th>
          <td>
            
              Sepp Hochreiter will be talking about “Hopfield Networks” at the next IARAI seminar on December 15th, 4PM CET.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 15, 2016</th>
          <td>
            
              A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 7, 2015</th>
          <td>
            
              <a class="news-title" href="/duo-iml/news/announcement_2/">A long announcement with details</a>
            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 22, 2015</th>
          <td>
            
              A simple inline announcement.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

              
        </div>
        <div class="col-sm mt-3 mt-md-0">
            
              <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="adler2020cross" class="col-sm-8">
    
      <div class="title">Cross-Domain Few-Shot Learning by Representation Fusion</div>
      <div class="author">
        
          
            
              
                
                  Adler, Thomas,
                
              
            
          
        
          
            
              
                
                  Brandstetter, Johannes,
                
              
            
          
        
          
            
              
                
                  Widrich, Michael,
                
              
            
          
        
          
            
              
                
                  Mayr, Andreas,
                
              
            
          
        
          
            
              
                
                  Kreil, David,
                
              
            
          
        
          
            
              
                
                  Kopp, Michael,
                
              
            
          
        
          
            
              
                
                  Klambauer, Günter,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2010.06498</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2010.06498" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Neurips</abbr>
    
  
  </div>

  <div id="heuselGANsTrainedTwo2017" class="col-sm-8">
    
      <div class="title">GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</div>
      <div class="author">
        
          
            
              
                
                  Heusel, Martin,
                
              
            
          
        
          
            
              
                
                  Ramsauer, Hubert,
                
              
            
          
        
          
            
              
                
                  Unterthiner, Thomas,
                
              
            
          
        
          
            
              
                
                  Nessler, Bernhard,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1706.08500" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="http://arxiv.org/pdf/1706.08500.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the "Fr\’echet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="ramsauerHopfieldNetworksAll2020" class="col-sm-8">
    
      <div class="title">Hopfield Networks Is All You Need</div>
      <div class="author">
        
          
            
              
                
                  Ramsauer, Hubert,
                
              
            
          
        
          
            
              
                
                  Schäfl, Bernhard,
                
              
            
          
        
          
            
              
                
                  Lehner, Johannes,
                
              
            
          
        
          
            
              
                
                  Seidl, Philipp,
                
              
            
          
        
          
            
              
                
                  Widrich, Michael,
                
              
            
          
        
          
            
              
                
                  Gruber, Lukas,
                
              
            
          
        
          
            
              
                
                  Holzleitner, Markus,
                
              
            
          
        
          
            
              
                
                  Pavlović, Milena,
                
              
            
          
        
          
            
              
                
                  Sandve, Geir Kjetil,
                
              
            
          
        
          
            
              
                
                  Greiff, Victor,
                
              
            
          
        
          
            
              
                
                  Kreil, David,
                
              
            
          
        
          
            
              
                
                  Kopp, Michael,
                
              
            
          
        
          
            
              
                
                  Klambauer, Günter,
                
              
            
          
        
          
            
              
                
                  Brandstetter, Johannes,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2008.02217" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="http://arxiv.org/pdf/2008.02217.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We show that the transformer attention mechanism is the update rule of a modern Hopfield network with continuous states. This new Hopfield network can store exponentially (with the dimension) many patterns, converges with one update, and has exponentially small retrieval errors. The number of stored patterns is traded off against convergence speed and retrieval error. The new Hopfield network has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. Transformer and BERT models operate in their first layers preferably in the global averaging regime, while they operate in higher layers in metastable states. The gradient in transformers is maximal for metastable states, is uniformly distributed for global averaging, and vanishes for a fixed point near a stored pattern. Using the Hopfield network interpretation, we analyzed learning of transformer and BERT models. Learning starts with attention heads that average and then most of them switch to metastable states. However, the majority of heads in the first layers still averages and can be replaced by averaging, e.g. our proposed Gaussian weighting. In contrast, heads in the last layers steadily learn and seem to use metastable states to collect information created in lower layers. These heads seem to be a promising target for improving transformers. Neural networks with Hopfield networks outperform other methods on immune repertoire classification, where the Hopfield net stores several hundreds of thousands of patterns. We provide a new PyTorch layer called "Hopfield", which allows to equip deep learning architectures with modern Hopfield networks as a new powerful concept comprising pooling, memory, and attention. GitHub: https://github.com/ml-jku/hopfield-layers</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="widrich2020modern" class="col-sm-8">
    
      <div class="title">Modern Hopfield networks and attention for immune repertoire classification</div>
      <div class="author">
        
          
            
              
                
                  Widrich, Michael,
                
              
            
          
        
          
            
              
                
                  Schäfl, Bernhard,
                
              
            
          
        
          
            
              
                
                  Ramsauer, Hubert,
                
              
            
          
        
          
            
              
                
                  Pavlović, Milena,
                
              
            
          
        
          
            
              
                
                  Gruber, Lukas,
                
              
            
          
        
          
            
              
                
                  Holzleitner, Markus,
                
              
            
          
        
          
            
              
                
                  Brandstetter, Johannes,
                
              
            
          
        
          
            
              
                
                  Sandve, Geir Kjetil,
                
              
            
          
        
          
            
              
                
                  Greiff, Victor,
                
              
            
          
        
          
            
              
                
                  Hochreiter, Sepp,
                
              
            
          
        
          
            
              
                
                  and others, 
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2007.13505</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2007.13505" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="patil2020alignrudder" class="col-sm-8">
    
      <div class="title">Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution</div>
      <div class="author">
        
          
            
              
                
                  Patil, Vihang P.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, Markus,
                
              
            
          
        
          
            
              
                
                  Dinu, Marius-Constantin,
                
              
            
          
        
          
            
              
                
                  Dorfer, Matthias,
                
              
            
          
        
          
            
              
                
                  Blies, Patrick M.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, Johannes,
                
              
            
          
        
          
            
              
                
                  Arjona-Medina, Jose A.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2009.14108</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2009.14108" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2009.14108.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Reinforcement Learning algorithms require a large number of samples to solve complex tasks with sparse and delayed rewards. Complex tasks can often be hierarchically decomposed into sub-tasks. A step in the Q-function can be associated with solving a sub-task, where the expectation of the return increases. RUDDER has been introduced to identify these steps and then redistribute reward to them, thus immediately giving reward if sub-tasks are solved. Since the problem of delayed rewards is mitigated, learning is considerably sped up. However, for complex tasks, current exploration strategies as deployed in RUDDER struggle with discovering episodes with high rewards. Therefore, we assume that episodes with high rewards are given as demonstrations and do not have to be discovered by exploration. Typically the number of demonstrations is small and RUDDER’s LSTM model as a deep learning method does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER with two major modifications. First, Align-RUDDER assumes that episodes with high rewards are given as demonstrations, replacing RUDDER’s safe exploration and lessons replay buffer. Second, we replace RUDDER’s LSTM model by a profile model that is obtained from multiple sequence alignment of demonstrations. Profile models can be constructed from as few as two demonstrations as known from bioinformatics. Align-RUDDER inherits the concept of reward redistribution, which considerably reduces the delay of rewards, thus speeding up learning. Align-RUDDER outperforms competitors on complex artificial tasks with delayed reward and few demonstrations. On the MineCraft ObtainDiamond task, Align-RUDDER is able to mine a diamond, though not frequently.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="klotz2020learning" class="col-sm-8">
    
      <div class="title">Learning from mistakes: Online updating for deep learning models.</div>
      <div class="author">
        
          
            
              
                
                  Klotz, Daniel,
                
              
            
          
        
          
            
              
                
                  Kratzert, Frederik,
                
              
            
          
        
          
            
              
                
                  Sampson, Alden K,
                
              
            
          
        
          
            
              
                
                  Klambauer, Günter,
                
              
            
          
        
          
            
              
                
                  Hochreiter, Sepp,
                
              
            
          
        
          
            
              
                
                  and Nearing, Grey
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In EGU General Assembly Conference Abstracts</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="renz2020failure" class="col-sm-8">
    
      <div class="title">On failure modes of molecule generators and optimizers</div>
      <div class="author">
        
          
            
              
                
                  Renz, Philipp,
                
              
            
          
        
          
            
              
                
                  Van Rompaey, Dries,
                
              
            
          
        
          
            
              
                
                  Wegner, Jörg Kurt,
                
              
            
          
        
          
            
              
                
                  Hochreiter, Sepp,
                
              
            
          
        
          
            
              
                
                  and Klambauer, Günter
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="mayr2020lsc" class="col-sm-8">
    
      <div class="title">The LSC Benchmark Dataset: Technical Appendix and Partial Reanalysis</div>
      <div class="author">
        
          
            
              
                
                  Mayr, Andreas,
                
              
            
          
        
          
            
              
                
                  Klambauer, Günter,
                
              
            
          
        
          
            
              
                
                  Unterthiner, Thomas,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="hofmarcherLargescaleLigandbasedVirtual2020" class="col-sm-8">
    
      <div class="title">Large-Scale Ligand-Based Virtual Screening for SARS-CoV-2 Inhibitors Using Deep Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Hofmarcher, Markus,
                
              
            
          
        
          
            
              
                
                  Mayr, Andreas,
                
              
            
          
        
          
            
              
                
                  Rumetshofer, Elisabeth,
                
              
            
          
        
          
            
              
                
                  Ruch, Peter,
                
              
            
          
        
          
            
              
                
                  Renz, Philipp,
                
              
            
          
        
          
            
              
                
                  Schimunek, Johannes,
                
              
            
          
        
          
            
              
                
                  Seidl, Philipp,
                
              
            
          
        
          
            
              
                
                  Vall, Andreu,
                
              
            
          
        
          
            
              
                
                  Widrich, Michael,
                
              
            
          
        
          
            
              
                
                  Hochreiter, Sepp,
                
              
            
          
        
          
            
              
                
                  and Klambauer, Günter
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2004.00979" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="http://arxiv.org/pdf/2004.00979.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Due to the current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs. We conducted a large-scale virtual screening for small molecules that are potential CoV-2 inhibitors. To this end, we utilized "ChemAI", a deep neural network trained on more than 220M data points across 3.6M molecules from three public drug-discovery databases. With ChemAI, we screened and ranked one billion molecules from the ZINC database for favourable effects against CoV-2. We then reduced the result to the 30,000 top-ranked compounds, which are readily accessible and purchasable via the ZINC database. Additionally, we screened the DrugBank using ChemAI to allow for drug repurposing, which would be a fast way towards a therapy. We provide these top-ranked compounds of ZINC and DrugBank as a library for further screening with bioassays at https://github.com/ml-jku/sars-cov-inhibitors-chemai.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="Arjona:19" class="col-sm-8">
    
      <div class="title">RUDDER: Return Decomposition for Delayed Rewards</div>
      <div class="author">
        
          
            
              
                
                  Arjona-Medina, J. A.,
                
              
            
          
        
          
            
              
                
                  Gillhofer, M.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems 32</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1806.07857" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose RUDDER, a novel reinforcement learning approach for delayed rewards in finite Markov decision processes (MDPs). In MDPs the Q-values are equal to the expected immediate reward plus the expected future rewards. The latter are related to bias problems in temporal difference (TD) learning and to high variance problems in Monte Carlo (MC) learning. Both problems are even more severe when rewards are delayed. RUDDER aims at making the expected future rewards zero, which simplifies Q-value estimation to computing the mean of the immediate reward. We propose the following two new concepts to push the expected future rewards toward zero. (i) Reward redistribution that leads to return-equivalent decision processes with the same optimal policies and, when optimal, zero expected future rewards. (ii) Return decomposition via contribution analysis which transforms the reinforcement learning task into a regression task at which deep learning excels. On artificial tasks with delayed rewards, RUDDER is significantly faster than MC and exponentially faster than Monte Carlo Tree Search (MCTS), TD({λ}), and reward shaping approaches. At Atari games, RUDDER on top of a Proximal Policy Optimization (PPO) baseline improves the scores, which is most prominent at games with delayed rewards. Source code is available at \url{https://github.com/ml-jku/rudder} and demonstration videos at \url{https://goo.gl/EQerZV}.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AGUFM</abbr>
    
  
  </div>

  <div id="nearing2019large" class="col-sm-8">
    
      <div class="title">Large-Scale Rainfall-Runoff Modeling using the Long Short-Term Memory Network</div>
      <div class="author">
        
          
            
              
                
                  Nearing, GS,
                
              
            
          
        
          
            
              
                
                  Kratzert, F,
                
              
            
          
        
          
            
              
                
                  Klotz, D,
                
              
            
          
        
          
            
              
                
                  Klambauer, G,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>AGUFM</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="klambauer2017self" class="col-sm-8">
    
      <div class="title">Self-Normalizing Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Klambauer, Günter,
                
              
            
          
        
          
            
              
                
                  Unterthiner, Thomas,
                
              
            
          
        
          
            
              
                
                  Mayr, Andreas,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems 30</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div>

  <div id="unterthinerCoulombGANsProvably2018" class="col-sm-8">
    
      <div class="title">Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields</div>
      <div class="author">
        
          
            
              
                
                  Unterthiner, Thomas,
                
              
            
          
        
          
            
              
                
                  Nessler, Bernhard,
                
              
            
          
        
          
            
              
                
                  Seward, Calvin,
                
              
            
          
        
          
            
              
                
                  Klambauer, Günter,
                
              
            
          
        
          
            
              
                
                  Heusel, Martin,
                
              
            
          
        
          
            
              
                
                  Ramsauer, Hubert,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, Sepp
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/1708.08819" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field of charged particles, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples.</p>
    </div>
    
  </div>
</div>
</li>
</ol>
</div>

              
        </div>
    </div>
    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D"><i class="fas fa-envelope"></i></a>
  
  
  
  
  
  
  
  
  
  
  
  
</span>

      <div class="contact-note">You can even add a little note about which of these is the best way to reach you.
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2020 Institute for Machine Learning @ JKU.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/duo-iml/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/duo-iml/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/duo-iml/assets/js/dark_mode.js"></script>


</html>
